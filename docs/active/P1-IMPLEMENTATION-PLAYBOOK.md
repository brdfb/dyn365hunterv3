# P1 Implementation Playbook

**Tarih**: 2025-01-28  
**Durum**: âœ… **P1 TamamlandÄ± (2025-01-28)** - Reference Guide (Test KomutlarÄ±, Rollback ReÃ§eteleri, Risky Scenarios)  
**Referans**: `docs/active/KALAN-ISLER-PRIORITY.md` - P1 maddeleri tamamlandÄ±, P2 backlog

---

## ğŸ“‹ Ä°Ã§indekiler

1. [Branch Stratejisi](#branch-stratejisi)
2. [Commit Pattern](#commit-pattern)
3. [Test KomutlarÄ±](#test-komutlarÄ±)
4. [Risky Scenario SimulasyonlarÄ±](#risky-scenario-simulasyonlarÄ±)
5. [Rollback ReÃ§eteleri](#rollback-reÃ§eteleri)
6. [Release Pipeline](#release-pipeline)

---

## ğŸŒ¿ Branch Stratejisi

### Branch Naming Convention

**Format**: `p1/{madde-kÄ±sa-adÄ±}`

**P1 Branch'leri (SÄ±ralama Ã–nemli):**

```bash
# 1. Alembic Migration (EN Ã–NCE)
git checkout -b p1/alembic-migration

# 2. Distributed Rate Limiting
git checkout -b p1/distributed-rate-limiting

# 3. Caching Layer
git checkout -b p1/caching-layer

# 4. Bulk Operations
git checkout -b p1/bulk-operations

# 5. API Versioning (EN SON)
git checkout -b p1/api-versioning
```

### Branch Workflow

```bash
# 1. Main'den yeni branch oluÅŸtur
git checkout main
git pull origin main
git checkout -b p1/alembic-migration

# 2. Implementasyon yap
# ... kod deÄŸiÅŸiklikleri ...

# 3. Test et
bash scripts/run-tests-docker.sh

# 4. Commit et (commit pattern'e uygun)
git add .
git commit -m "feat: add Alembic migration system"

# 5. Push et
git push origin p1/alembic-migration

# 6. PR oluÅŸtur (GitHub)
# PR title: "P1: Alembic Migration System"
# PR description: Risk matrix'ten mitigation stratejilerini ekle
```

### Branch Merge SÄ±rasÄ±

**âš ï¸ KRÄ°TÄ°K**: Branch'ler baÄŸÄ±mlÄ±lÄ±k sÄ±rasÄ±na gÃ¶re merge edilmeli:

1. `p1/alembic-migration` â†’ `main` (ilk merge)
2. `p1/distributed-rate-limiting` â†’ `main` (Alembic sonrasÄ±)
3. `p1/caching-layer` â†’ `main` (DRL sonrasÄ±)
4. `p1/bulk-operations` â†’ `main` (Caching sonrasÄ±)
5. `p1/api-versioning` â†’ `main` (en son)

**Merge Checklist:**
- [ ] TÃ¼m testler geÃ§iyor mu? (`bash scripts/run-tests-docker.sh`)
- [ ] Lint hatalarÄ± yok mu? (`docker-compose exec api flake8 app/`)
- [ ] Type check geÃ§iyor mu? (`docker-compose exec api mypy app/`)
- [ ] Risk matrix'teki test senaryolarÄ± Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± mÄ±?
- [ ] Rollback reÃ§etesi test edildi mi?
- [ ] Documentation gÃ¼ncellendi mi? (CHANGELOG.md, README.md)

---

## ğŸ“ Commit Pattern

### Commit Message Format

**Conventional Commits** standardÄ± kullanÄ±lÄ±r:

```
<type>: <subject>

<body>

<footer>
```

### Commit Types

- `feat`: Yeni feature (P1 maddeleri iÃ§in)
- `fix`: Bug fix
- `refactor`: Code refactoring
- `test`: Test ekleme/gÃ¼ncelleme
- `docs`: Documentation gÃ¼ncelleme
- `chore`: Build/config deÄŸiÅŸiklikleri

### P1 Commit Ã–rnekleri

#### 1. Alembic Migration

```bash
git commit -m "feat: add Alembic migration system

- Alembic setup and configuration
- Base revision from current production schema
- Migrated 7 manual SQL migrations to Alembic format
- Added schema drift detection (alembic --autogenerate dry-run)
- Migration history tracking and rollback capability

Risk Mitigation:
- Base revision snapshot verified
- Rollback tests passed (alembic downgrade -1)
- Schema drift check implemented

Closes: P1-1 (Alembic Migration)"
```

#### 2. Distributed Rate Limiting

```bash
git commit -m "feat: implement Redis-based distributed rate limiting

- Redis-based rate limiting for DNS/WHOIS/API keys
- Circuit breaker + fallback to in-memory limiter
- Degrade mode logging (WARN level, Sentry tag)
- Multi-worker rate limiting support

Risk Mitigation:
- Circuit breaker tested (Redis down scenario)
- Fallback to in-memory verified
- Multi-worker test passed (2 workers, same API key)

Closes: P1-2 (Distributed Rate Limiting)"
```

#### 3. Caching Layer

```bash
git commit -m "feat: add Redis-based distributed caching layer

- DNS cache (1 hour TTL)
- WHOIS cache (24 hour TTL, migrated from in-memory)
- Provider mapping cache (24 hour TTL)
- Scoring cache (1 hour TTL, signals hash)
- Domain-level full scan cache (1 hour TTL)

Cache Key Design:
- dns:{domain}
- whois:{domain}
- provider:{mx_root}
- scoring:{domain}:{provider}:{signals_hash}
- scan:{domain}

Signals Hash: sha256(json.dumps(signals, sort_keys=True).encode())[:16]
TTL Alignment: Scan cache TTL <= DNS/WHOIS TTL (max 1 hour)

Risk Mitigation:
- TTL alignment verified
- Cache hit rate metrics added
- Versioned cache keys for future invalidation

Closes: P1-3 (Caching Layer)"
```

#### 4. Bulk Operations

```bash
git commit -m "feat: optimize bulk operations with batch processing

- Batch insert optimization (bulk_insert_mappings)
- Database transaction optimization (100 domain/batch)
- Deadlock prevention strategy (transaction timeout, retry)
- Batch failure recovery (partial commit log)
- Bulk log context (bulk_id, batch_no, total_batches)
- Rate-limit aware batch size calculation

Risk Mitigation:
- Deadlock scenario tested (2 workers, same domains)
- Batch failure recovery verified (DB down, Redis down)
- Partial commit log tested (100 domain, 50 success, 50 fail)

Closes: P1-4 (Bulk Operations)"
```

#### 5. API Versioning

```bash
git commit -m "feat: implement API versioning with backward compatibility

- API versioning structure (/api/v1/, /api/v2/)
- All 14 routers moved to /api/v1/
- Dual-path routing (v1 + legacy /api/...)
- Zero downtime deployment strategy
- Version deprecation policy (v1 supported for 6 months)

Risk Mitigation:
- Backward compatibility tests passed
- Zero downtime deployment verified
- Legacy endpoint redirects working

Closes: P1-5 (API Versioning)"
```

### Commit Checklist (Her Commit Ã–ncesi)

- [ ] Code formatted (`black app/`)
- [ ] Lint errors fixed (`flake8 app/`)
- [ ] Type hints present
- [ ] Tests passing (`bash scripts/run-tests-docker.sh`)
- [ ] Commit message follows pattern
- [ ] Related documentation updated (if needed)

---

## ğŸ§ª Test KomutlarÄ±

### Genel Test KomutlarÄ±

#### Docker'da Test Ã‡alÄ±ÅŸtÄ±rma (Ã–nerilen)

```bash
# TÃ¼m testler
bash scripts/run-tests-docker.sh

# Veya direkt:
docker-compose exec api pytest tests/ -v --tb=short

# Coverage ile:
docker-compose exec api pytest tests/ -v --cov=app --cov-report=term

# Belirli test dosyasÄ±:
docker-compose exec api pytest tests/test_alembic.py -v

# Belirli test fonksiyonu:
docker-compose exec api pytest tests/test_alembic.py::test_migration_rollback -v
```

#### Local Test (Venv Gerekli)

```bash
# Venv aktive et
source .venv/bin/activate  # Linux/Mac
# veya
.venv\Scripts\activate     # Windows

# Test Ã§alÄ±ÅŸtÄ±r
pytest tests/ -v --cov=app --cov-report=term
```

### P1-Specific Test KomutlarÄ±

#### 1. Alembic Migration Tests

```bash
# Alembic migration test
docker-compose exec api alembic upgrade head
docker-compose exec api alembic downgrade -1
docker-compose exec api alembic upgrade head

# Schema drift check
docker-compose exec api alembic --autogenerate --dry-run

# Migration history check
docker-compose exec postgres psql -U dyn365hunter -d dyn365hunter -c "SELECT * FROM alembic_version;"
```

#### 2. Distributed Rate Limiting Tests

```bash
# Multi-worker rate limiting test
# Terminal 1: Worker 1
docker-compose exec worker celery -A app.core.celery_app worker --loglevel=info --concurrency=1

# Terminal 2: Worker 2
docker-compose exec -d worker celery -A app.core.celery_app worker --loglevel=info --concurrency=1

# Terminal 3: Test script
docker-compose exec api python -c "
from app.core.rate_limiter import get_dns_rate_limiter
limiter = get_dns_rate_limiter()
for i in range(20):
    print(f'Request {i}: {limiter.acquire()}')
"

# Redis down test (circuit breaker)
docker-compose stop redis
# Test fallback to in-memory
docker-compose exec api pytest tests/test_rate_limiter.py::test_redis_down_fallback -v
docker-compose start redis
```

#### 3. Caching Layer Tests

```bash
# Cache hit rate test
docker-compose exec api python -c "
from app.core.cache import get_cached_dns_result, cache_dns_result
# First call (cache miss)
result1 = get_cached_dns_result('example.com')
print(f'First call: {result1}')
# Cache it
cache_dns_result('example.com', {'mx_root': 'outlook.com'}, ttl=3600)
# Second call (cache hit)
result2 = get_cached_dns_result('example.com')
print(f'Second call: {result2}')
"

# Redis cache inspection
docker-compose exec redis redis-cli
> KEYS dns:*
> TTL dns:example.com
> GET dns:example.com

# Provider mapping cache test
docker-compose exec api pytest tests/test_cache.py::test_provider_cache_hit -v

# Scoring cache test (signals hash stability)
docker-compose exec api pytest tests/test_cache.py::test_scoring_cache_hash_stability -v
```

#### 4. Bulk Operations Tests

```bash
# Deadlock test (2 workers, same domains)
# Terminal 1: Worker 1
docker-compose exec worker celery -A app.core.celery_app worker --loglevel=info

# Terminal 2: Bulk scan job (100 domains)
curl -X POST http://localhost:8000/scan/bulk \
  -H "Content-Type: application/json" \
  -d '{"domain_list": ["example.com", "google.com", ...]}'

# Terminal 3: Monitor logs
docker-compose logs -f worker | grep -i deadlock

# Batch failure recovery test
# Simulate DB down
docker-compose stop postgres
# Start bulk scan
curl -X POST http://localhost:8000/scan/bulk ...
# Check partial commit log
docker-compose exec api python -c "
from app.core.tasks import get_bulk_log_context
print(get_bulk_log_context('job_id'))
"
docker-compose start postgres
```

#### 5. API Versioning Tests

```bash
# Backward compatibility test
# Old endpoint (should still work)
curl "http://localhost:8000/leads?segment=Migration"

# New endpoint (v1)
curl "http://localhost:8000/api/v1/leads?segment=Migration"

# Both should return same result
curl "http://localhost:8000/leads?segment=Migration" > old.json
curl "http://localhost:8000/api/v1/leads?segment=Migration" > new.json
diff old.json new.json

# Zero downtime deployment test
# Deploy new version while old version running
# Check both endpoints work
```

### Test Coverage Targets

- **P1 Maddeleri**: â‰¥80% coverage (HIGH risk iÃ§in)
- **Genel**: â‰¥70% coverage (mevcut hedef)
- **Critical paths**: 100% coverage (migration, rollback, circuit breaker)

---

## âš ï¸ Risky Scenario SimulasyonlarÄ±

### 1. Alembic Migration - Risky Scenarios

#### Scenario 1.1: Migration Drift (Schema Mismatch)

**SimÃ¼lasyon:**
```bash
# 1. Production DB'de manuel deÄŸiÅŸiklik yap (simÃ¼le et)
docker-compose exec postgres psql -U dyn365hunter -d dyn365hunter -c "
ALTER TABLE companies ADD COLUMN test_column VARCHAR(50);
"

# 2. Alembic autogenerate Ã§alÄ±ÅŸtÄ±r
docker-compose exec api alembic --autogenerate -m "test_migration"

# 3. Diff kontrolÃ¼ yap (schema drift tespit edilmeli)
docker-compose exec api alembic --autogenerate --dry-run

# 4. Manuel diff ile doÄŸrula
docker-compose exec api alembic revision --autogenerate -m "manual_diff_check"
```

**Beklenen SonuÃ§:**
- Alembic drift tespit etmeli
- Manuel diff ile doÄŸrulanmalÄ±
- Migration oluÅŸturulmadan Ã¶nce onay alÄ±nmalÄ±

#### Scenario 1.2: Downgrade Fail

**SimÃ¼lasyon:**
```bash
# 1. Migration'Ä± uygula
docker-compose exec api alembic upgrade head

# 2. Downgrade dene
docker-compose exec api alembic downgrade -1

# 3. Downgrade baÅŸarÄ±sÄ±z olursa (data loss riski)
# Rollback reÃ§etesi uygula (aÅŸaÄŸÄ±da)
```

**Beklenen SonuÃ§:**
- Downgrade baÅŸarÄ±lÄ± olmalÄ±
- Data loss olmamalÄ±
- Rollback reÃ§etesi hazÄ±r olmalÄ±

#### Scenario 1.3: Production Schema Mismatch

**SimÃ¼lasyon:**
```bash
# 1. Production-like DB'de test et
docker-compose exec postgres psql -U dyn365hunter -d dyn365hunter -c "
-- Production schema'yÄ± simÃ¼le et
CREATE TABLE IF NOT EXISTS test_table (id SERIAL PRIMARY KEY);
"

# 2. Alembic base revision oluÅŸtur
docker-compose exec api alembic revision --autogenerate -m "base_revision"

# 3. Base revision'Ä± doÄŸrula
docker-compose exec api alembic history
```

**Beklenen SonuÃ§:**
- Base revision production schema'yÄ± yansÄ±tmalÄ±
- Manuel diff ile doÄŸrulanmalÄ±

---

### 2. Distributed Rate Limiting - Risky Scenarios

#### Scenario 2.1: Redis Unavailable

**SimÃ¼lasyon:**
```bash
# 1. Redis'i durdur
docker-compose stop redis

# 2. Rate limiting isteÄŸi yap
curl -X POST http://localhost:8000/scan/domain \
  -H "Content-Type: application/json" \
  -d '{"domain": "example.com"}'

# 3. Circuit breaker devreye girmeli
docker-compose logs api | grep -i "circuit.*breaker"

# 4. Fallback to in-memory Ã§alÄ±ÅŸmalÄ±
docker-compose logs api | grep -i "fallback.*in-memory"

# 5. Degrade mode log kontrolÃ¼
docker-compose logs api | grep -i "WARN.*degrade"
```

**Beklenen SonuÃ§:**
- Circuit breaker devreye girmeli
- Fallback to in-memory Ã§alÄ±ÅŸmalÄ±
- WARN level log + Sentry tag

#### Scenario 2.2: Limiter Mismatch (Multi-Worker)

**SimÃ¼lasyon:**
```bash
# 1. 2 worker baÅŸlat
docker-compose up -d worker
docker-compose scale worker=2

# 2. AynÄ± API key ile 100 request yap (rate limit: 60 req/min)
for i in {1..100}; do
  curl -X POST http://localhost:8000/ingest/webhook \
    -H "X-API-Key: test-key" \
    -H "Content-Type: application/json" \
    -d '{"domain": "example.com"}'
done

# 3. Rate limit kontrolÃ¼ (her iki worker'da aynÄ± limit)
docker-compose logs worker | grep -i "rate.*limit"
```

**Beklenen SonuÃ§:**
- Her iki worker aynÄ± rate limit'i kullanmalÄ±
- Toplam limit: 60 req/min (distributed)
- Redis'te shared counter olmalÄ±

---

### 3. Caching Layer - Risky Scenarios

#### Scenario 3.1: Stale Cache (TTL Mismatch)

**SimÃ¼lasyon:**
```bash
# 1. DNS cache'e kaydet (1 saat TTL)
docker-compose exec api python -c "
from app.core.cache import cache_dns_result
cache_dns_result('example.com', {'mx_root': 'old.outlook.com'}, ttl=3600)
"

# 2. Domain'i tekrar scan et (cache hit olmalÄ±)
curl -X POST http://localhost:8000/scan/domain \
  -H "Content-Type: application/json" \
  -d '{"domain": "example.com"}'

# 3. Cache'teki deÄŸer kontrol et
docker-compose exec redis redis-cli GET "dns:example.com"

# 4. TTL kontrolÃ¼ (1 saat = 3600 saniye)
docker-compose exec redis redis-cli TTL "dns:example.com"
```

**Beklenen SonuÃ§:**
- Cache hit olmalÄ±
- TTL doÄŸru olmalÄ± (3600 saniye)
- Stale cache riski minimize edilmeli

#### Scenario 3.2: Signals Hash Instability

**SimÃ¼lasyon:**
```bash
# 1. AynÄ± signals ile 2 kez hash oluÅŸtur
docker-compose exec api python -c "
import hashlib
import json

signals1 = {'spf': True, 'dkim': True, 'dmarc_policy': 'reject'}
signals2 = {'dkim': True, 'spf': True, 'dmarc_policy': 'reject'}  # FarklÄ± sÄ±ra

hash1 = hashlib.sha256(json.dumps(signals1, sort_keys=True).encode()).hexdigest()[:16]
hash2 = hashlib.sha256(json.dumps(signals2, sort_keys=True).encode()).hexdigest()[:16]

print(f'Hash1: {hash1}')
print(f'Hash2: {hash2}')
print(f'Match: {hash1 == hash2}')  # True olmalÄ±
"
```

**Beklenen SonuÃ§:**
- `sort_keys=True` ile hash stabil olmalÄ±
- AynÄ± signals â†’ aynÄ± hash

#### Scenario 3.3: Cache Consistency Loss

**SimÃ¼lasyon:**
```bash
# 1. Scan cache'e kaydet (1 saat TTL)
docker-compose exec api python -c "
from app.core.cache import cache_scan_result
cache_scan_result('example.com', {'score': 75}, ttl=3600)
"

# 2. DNS cache'i expire et (simÃ¼le et - TTL'i 0 yap)
docker-compose exec redis redis-cli EXPIRE "dns:example.com" 0

# 3. Scan cache hala var mÄ± kontrol et
docker-compose exec redis redis-cli GET "scan:example.com"

# 4. TTL uyumu kontrolÃ¼ (scan TTL <= DNS TTL)
docker-compose exec redis redis-cli TTL "scan:example.com"
docker-compose exec redis redis-cli TTL "dns:example.com"
```

**Beklenen SonuÃ§:**
- Scan cache TTL <= DNS TTL (konsistensi)
- Cache invalidation stratejisi Ã§alÄ±ÅŸmalÄ±

---

### 4. Bulk Operations - Risky Scenarios

#### Scenario 4.1: Deadlock (2 Workers, Same Domains)

**SimÃ¼lasyon:**
```bash
# 1. 2 worker baÅŸlat
docker-compose up -d worker
docker-compose scale worker=2

# 2. AynÄ± domain'leri 2 farklÄ± bulk scan job'Ä±na ekle
curl -X POST http://localhost:8000/scan/bulk \
  -H "Content-Type: application/json" \
  -d '{"domain_list": ["example.com", "google.com"]}'

# Job ID 1 al
JOB_ID_1=$(curl -s -X POST http://localhost:8000/scan/bulk ... | jq -r '.job_id')

# AynÄ± domain'lerle 2. job oluÅŸtur
curl -X POST http://localhost:8000/scan/bulk \
  -H "Content-Type: application/json" \
  -d '{"domain_list": ["example.com", "google.com"]}'

# Job ID 2 al
JOB_ID_2=$(curl -s -X POST http://localhost:8000/scan/bulk ... | jq -r '.job_id')

# 3. Deadlock log'larÄ±nÄ± izle
docker-compose logs -f worker | grep -i "deadlock\|timeout\|lock"
```

**Beklenen SonuÃ§:**
- Deadlock olmamalÄ± (transaction timeout + retry)
- Batch isolation Ã§alÄ±ÅŸmalÄ±
- Partial commit log oluÅŸmalÄ±

#### Scenario 4.2: Batch Corruption

**SimÃ¼lasyon:**
```bash
# 1. 100 domain'lik bulk scan baÅŸlat
curl -X POST http://localhost:8000/scan/bulk \
  -H "Content-Type: application/json" \
  -d '{"domain_list": ["domain1.com", "domain2.com", ...]}'

# 2. Batch ortasÄ±nda DB'yi durdur (simÃ¼le et)
docker-compose stop postgres

# 3. Batch failure recovery kontrolÃ¼
docker-compose logs worker | grep -i "batch.*failure\|partial.*commit"

# 4. Partial commit log kontrolÃ¼
docker-compose exec api python -c "
from app.core.tasks import get_partial_commit_log
log = get_partial_commit_log('job_id')
print(f'Committed: {log[\"committed\"]}')
print(f'Failed: {log[\"failed\"]}')
"

# 5. DB'yi baÅŸlat
docker-compose start postgres

# 6. Retry mekanizmasÄ± Ã§alÄ±ÅŸmalÄ±
docker-compose logs worker | grep -i "retry\|recovery"
```

**Beklenen SonuÃ§:**
- Partial commit log oluÅŸmalÄ±
- Batch failure recovery Ã§alÄ±ÅŸmalÄ±
- Retry mekanizmasÄ± devreye girmeli

#### Scenario 4.3: Transaction Timeout

**SimÃ¼lasyon:**
```bash
# 1. Uzun sÃ¼ren batch iÅŸlemi (simÃ¼le et - DB lock)
docker-compose exec postgres psql -U dyn365hunter -d dyn365hunter -c "
BEGIN;
LOCK TABLE domain_signals IN EXCLUSIVE MODE;
-- Bu lock'u 30 saniye tut (timeout test iÃ§in)
SELECT pg_sleep(30);
COMMIT;
"

# 2. AynÄ± anda bulk scan baÅŸlat
curl -X POST http://localhost:8000/scan/bulk ...

# 3. Transaction timeout kontrolÃ¼
docker-compose logs worker | grep -i "timeout\|transaction"
```

**Beklenen SonuÃ§:**
- Transaction timeout Ã§alÄ±ÅŸmalÄ±
- Retry logic devreye girmeli
- Deadlock prevention Ã§alÄ±ÅŸmalÄ±

---

### 5. API Versioning - Risky Scenarios

#### Scenario 5.1: 404/Route Mismatch

**SimÃ¼lasyon:**
```bash
# 1. Eski endpoint'i test et (hala Ã§alÄ±ÅŸmalÄ±)
curl "http://localhost:8000/leads?segment=Migration"

# 2. Yeni endpoint'i test et
curl "http://localhost:8000/api/v1/leads?segment=Migration"

# 3. Her iki endpoint de 200 OK dÃ¶nmeli
# 4. Response'lar aynÄ± olmalÄ±
```

**Beklenen SonuÃ§:**
- Her iki endpoint Ã§alÄ±ÅŸmalÄ±
- Response'lar aynÄ± olmalÄ±
- 404 hatasÄ± olmamalÄ±

#### Scenario 5.2: Backward Compatibility Break

**SimÃ¼lasyon:**
```bash
# 1. Eski client (legacy endpoint kullanÄ±yor)
curl "http://localhost:8000/leads?segment=Migration" > old_response.json

# 2. Yeni client (v1 endpoint kullanÄ±yor)
curl "http://localhost:8000/api/v1/leads?segment=Migration" > new_response.json

# 3. Response format kontrolÃ¼
diff old_response.json new_response.json

# 4. Response schema kontrolÃ¼ (Pydantic models)
docker-compose exec api python -c "
from app.api.leads import LeadsListResponse
# Her iki response da LeadsListResponse model'ine uymalÄ±
"
```

**Beklenen SonuÃ§:**
- Response format aynÄ± olmalÄ±
- Pydantic validation geÃ§meli
- Backward compatibility korunmalÄ±

#### Scenario 5.3: Zero Downtime Deployment Failure

**SimÃ¼lasyon:**
```bash
# 1. Deployment sÄ±rasÄ±nda test (rolling update simÃ¼lasyonu)
# Old version Ã§alÄ±ÅŸÄ±yor
curl "http://localhost:8000/leads?segment=Migration"

# 2. New version deploy et (Docker restart)
docker-compose restart api

# 3. Deployment sÄ±rasÄ±nda her iki endpoint Ã§alÄ±ÅŸmalÄ±
curl "http://localhost:8000/leads?segment=Migration"  # Old
curl "http://localhost:8000/api/v1/leads?segment=Migration"  # New

# 4. Zero downtime kontrolÃ¼
# Her iki endpoint de Ã§alÄ±ÅŸmalÄ±, hiÃ§ downtime olmamalÄ±
```

**Beklenen SonuÃ§:**
- Zero downtime deployment
- Her iki endpoint Ã§alÄ±ÅŸmalÄ±
- HiÃ§ 503/502 hatasÄ± olmamalÄ±

---

## ğŸ”„ Rollback ReÃ§eteleri

### Genel Rollback Stratejisi

**Rollback Ã–ncesi Checklist:**
- [ ] Rollback planÄ± hazÄ±r mÄ±?
- [ ] Rollback test edildi mi? (staging'de)
- [ ] Data backup alÄ±ndÄ± mÄ±? (production iÃ§in)
- [ ] Rollback sÃ¼resi tahmin edildi mi?
- [ ] Rollback sonrasÄ± test planÄ± hazÄ±r mÄ±?

---

### 1. Alembic Migration - Rollback

#### Rollback Senaryosu: Migration BaÅŸarÄ±sÄ±z

**ReÃ§ete:**

```bash
# 1. Migration durumunu kontrol et
docker-compose exec api alembic current

# 2. Son migration'Ä± geri al
docker-compose exec api alembic downgrade -1

# 3. Base'e kadar geri al (gerekirse)
docker-compose exec api alembic downgrade base

# 4. Schema durumunu kontrol et
docker-compose exec postgres psql -U dyn365hunter -d dyn365hunter -c "\d companies"

# 5. Data integrity kontrolÃ¼
docker-compose exec api pytest tests/test_migration_rollback.py -v

# 6. API health check
curl http://localhost:8000/healthz
```

**Rollback SonrasÄ±:**
- [ ] Schema eski haline dÃ¶ndÃ¼ mÃ¼?
- [ ] Data loss var mÄ±? (SELECT COUNT(*) kontrolÃ¼)
- [ ] API Ã§alÄ±ÅŸÄ±yor mu? (`/healthz` check)
- [ ] Testler geÃ§iyor mu?

**Rollback SÃ¼resi:** ~5-10 dakika (migration boyutuna gÃ¶re)

---

### 2. Distributed Rate Limiting - Rollback

#### Rollback Senaryosu: Redis Down + Circuit Breaker Fail

**ReÃ§ete:**

```bash
# 1. Redis'i durdur (simÃ¼le et)
docker-compose stop redis

# 2. Fallback to in-memory kontrolÃ¼
docker-compose logs api | grep -i "fallback.*in-memory"

# 3. EÄŸer fallback Ã§alÄ±ÅŸmÄ±yorsa, code rollback
git checkout main  # veya Ã¶nceki commit
git revert <commit-hash>

# 4. API'yi restart et
docker-compose restart api

# 5. Rate limiting test et
curl -X POST http://localhost:8000/scan/domain ...

# 6. In-memory rate limiting Ã§alÄ±ÅŸÄ±yor mu kontrol et
docker-compose logs api | grep -i "rate.*limit"
```

**Rollback SonrasÄ±:**
- [ ] In-memory rate limiting Ã§alÄ±ÅŸÄ±yor mu?
- [ ] API Ã§alÄ±ÅŸÄ±yor mu?
- [ ] Rate limit doÄŸru Ã§alÄ±ÅŸÄ±yor mu?

**Rollback SÃ¼resi:** ~2-5 dakika (code revert)

---

### 3. Caching Layer - Rollback

#### Rollback Senaryosu: Stale Cache + Consistency Loss

**ReÃ§ete:**

```bash
# 1. Cache'i temizle (tÃ¼m cache keys)
docker-compose exec redis redis-cli FLUSHDB

# 2. Cache'i devre dÄ±ÅŸÄ± bÄ±rak (code rollback)
# app/core/cache.py'de cache check'i skip et
git checkout main  # veya Ã¶nceki commit

# 3. API'yi restart et
docker-compose restart api

# 4. Cache olmadan test et
curl -X POST http://localhost:8000/scan/domain ...

# 5. Performance kontrolÃ¼ (cache olmadan yavaÅŸ olmalÄ±)
time curl -X POST http://localhost:8000/scan/domain ...
```

**Rollback SonrasÄ±:**
- [ ] Cache temizlendi mi?
- [ ] API cache olmadan Ã§alÄ±ÅŸÄ±yor mu?
- [ ] Performance acceptable mÄ±? (cache olmadan)

**Rollback SÃ¼resi:** ~2-5 dakika (cache flush + code revert)

---

### 4. Bulk Operations - Rollback

#### Rollback Senaryosu: Deadlock + Batch Corruption

**ReÃ§ete:**

```bash
# 1. Aktif bulk job'larÄ± durdur
docker-compose stop worker

# 2. Partial commit log kontrolÃ¼
docker-compose exec api python -c "
from app.core.tasks import get_partial_commit_log
log = get_partial_commit_log('job_id')
print(f'Committed domains: {log[\"committed\"]}')
print(f'Failed domains: {log[\"failed\"]}')
"

# 3. Failed domain'leri manuel olarak iÅŸle (gerekirse)
# Committed domain'ler zaten DB'de

# 4. Code rollback (deadlock prevention kaldÄ±r)
git checkout main  # veya Ã¶nceki commit

# 5. Worker'Ä± restart et
docker-compose restart worker

# 6. Failed domain'leri tekrar scan et (sequential, safe mode)
for domain in failed_domains; do
  curl -X POST http://localhost:8000/scan/domain ...
done
```

**Rollback SonrasÄ±:**
- [ ] Partial commit log kontrol edildi mi?
- [ ] Failed domain'ler manuel iÅŸlendi mi?
- [ ] Data consistency korundu mu?

**Rollback SÃ¼resi:** ~10-30 dakika (batch size'a gÃ¶re)

---

### 5. API Versioning - Rollback

#### Rollback Senaryosu: 404/Route Mismatch + BC Break

**ReÃ§ete:**

```bash
# 1. Legacy endpoint'leri kontrol et
curl "http://localhost:8000/leads?segment=Migration"

# 2. EÄŸer legacy endpoint Ã§alÄ±ÅŸmÄ±yorsa, code rollback
git checkout main  # veya Ã¶nceki commit

# 3. API'yi restart et
docker-compose restart api

# 4. Her iki endpoint'i test et
curl "http://localhost:8000/leads?segment=Migration"  # Legacy
curl "http://localhost:8000/api/v1/leads?segment=Migration"  # v1 (eÄŸer hala varsa)

# 5. Client compatibility test
# Eski client'lar Ã§alÄ±ÅŸÄ±yor mu?
```

**Rollback SonrasÄ±:**
- [ ] Legacy endpoint Ã§alÄ±ÅŸÄ±yor mu?
- [ ] Client compatibility korundu mu?
- [ ] Zero downtime saÄŸlandÄ± mÄ±?

**Rollback SÃ¼resi:** ~2-5 dakika (code revert)

---

## ğŸš€ Release Pipeline

### P1 Release Stratejisi

**Release SÄ±rasÄ± (BaÄŸÄ±mlÄ±lÄ±k SÄ±rasÄ±na GÃ¶re):**

1. **Alembic Migration** â†’ `main` (ilk release)
2. **Distributed Rate Limiting** â†’ `main` (Alembic sonrasÄ±)
3. **Caching Layer** â†’ `main` (DRL sonrasÄ±)
4. **Bulk Operations** â†’ `main` (Caching sonrasÄ±)
5. **API Versioning** â†’ `main` (en son)

### Release Pipeline AdÄ±mlarÄ±

#### Pre-Release Checklist

**Her P1 Maddesi Ä°Ã§in:**

- [ ] TÃ¼m testler geÃ§iyor mu? (`bash scripts/run-tests-docker.sh`)
- [ ] Lint hatalarÄ± yok mu? (`docker-compose exec api flake8 app/`)
- [ ] Type check geÃ§iyor mu? (`docker-compose exec api mypy app/`)
- [ ] Risk matrix'teki test senaryolarÄ± Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± mÄ±?
- [ ] Rollback reÃ§etesi test edildi mi? (staging'de)
- [ ] Documentation gÃ¼ncellendi mi? (CHANGELOG.md, README.md)
- [ ] Commit message pattern'e uygun mu?
- [ ] PR review tamamlandÄ± mÄ±?

#### Release AdÄ±mlarÄ±

**1. Branch Merge**

```bash
# 1. Main'i gÃ¼ncelle
git checkout main
git pull origin main

# 2. Feature branch'i merge et
git merge p1/alembic-migration --no-ff

# 3. Conflict kontrolÃ¼
git status

# 4. Merge commit message
git commit -m "Merge p1/alembic-migration into main

P1-1: Alembic Migration System
- Migration history tracking
- Rollback capability
- Schema drift detection

Risk: HIGH
Mitigation: Base revision snapshot, dry-run, rollback test"
```

**2. Test Suite (Post-Merge)**

```bash
# 1. TÃ¼m testler
bash scripts/run-tests-docker.sh

# 2. Integration testler
docker-compose exec api pytest tests/test_integration_p1.py -v

# 3. Risk matrix test senaryolarÄ±
bash scripts/test_p1_risky_scenarios.sh
```

**3. Documentation Update**

```bash
# 1. CHANGELOG.md gÃ¼ncelle
# [Unreleased] bÃ¶lÃ¼mÃ¼ne ekle:
# - P1-1: Alembic Migration System

# 2. README.md gÃ¼ncelle (gerekirse)
# - Alembic migration komutlarÄ± ekle

# 3. Commit et
git add CHANGELOG.md README.md
git commit -m "docs: update documentation for P1-1 Alembic Migration"
```

**4. Tag & Release**

```bash
# 1. Version tag oluÅŸtur (P1 maddeleri iÃ§in minor version bump)
# v1.0.0 â†’ v1.1.0 (P1 tamamlandÄ±ÄŸÄ±nda)

# 2. Tag oluÅŸtur
git tag -a v1.1.0 -m "Release v1.1.0: P1 Performance Improvements

P1-1: Alembic Migration System
P1-2: Distributed Rate Limiting
P1-3: Caching Layer
P1-4: Bulk Operations Optimization
P1-5: API Versioning"

# 3. Tag'Ä± push et
git push origin v1.1.0
```

**5. Production Deployment**

```bash
# 1. Production environment'a deploy
# (Docker Compose, Kubernetes, vb.)

# 2. Health check
curl https://api.example.com/healthz

# 3. Migration Ã§alÄ±ÅŸtÄ±r (Alembic iÃ§in)
docker-compose exec api alembic upgrade head

# 4. Smoke test
bash scripts/smoke_test_p1.sh

# 5. Monitor logs
docker-compose logs -f api | grep -i "error\|warn"
```

### Release Pipeline Checklist

**Her Release Ã–ncesi:**

- [ ] Pre-release checklist tamamlandÄ± mÄ±?
- [ ] Test suite geÃ§ti mi?
- [ ] Documentation gÃ¼ncellendi mi?
- [ ] Risk matrix test senaryolarÄ± Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± mÄ±?
- [ ] Rollback reÃ§etesi test edildi mi?
- [ ] Tag oluÅŸturuldu mu?
- [ ] Production deployment planÄ± hazÄ±r mÄ±?

**Her Release SonrasÄ±:**

- [ ] Production health check geÃ§ti mi?
- [ ] Smoke test geÃ§ti mi?
- [ ] Log monitoring aktif mi?
- [ ] Rollback planÄ± hazÄ±r mÄ±? (ilk 24 saat iÃ§in)

---

## ğŸ“Š P1 Release Timeline

### Hafta 1: Alembic + DRL

**GÃ¼n 1-3: Alembic Migration**
- Branch: `p1/alembic-migration`
- Test: Migration up/down, schema drift
- Release: `v1.1.0-alembic` (pre-release tag)

**GÃ¼n 4: Distributed Rate Limiting**
- Branch: `p1/distributed-rate-limiting`
- Test: Multi-worker, Redis down, circuit breaker
- Release: `v1.1.0-drl` (pre-release tag)

### Hafta 2: Caching + Bulk

**GÃ¼n 1-2: Caching Layer**
- Branch: `p1/caching-layer`
- Test: Cache hit rate, TTL alignment, signals hash
- Release: `v1.1.0-caching` (pre-release tag)

**GÃ¼n 3: Bulk Operations**
- Branch: `p1/bulk-operations`
- Test: Deadlock, batch failure, partial commit
- Release: `v1.1.0-bulk` (pre-release tag)

### Hafta 3: Versioning + Integration

**GÃ¼n 1: API Versioning**
- Branch: `p1/api-versioning`
- Test: Backward compatibility, zero downtime
- Release: `v1.1.0-versioning` (pre-release tag)

**GÃ¼n 2-3: Integration & Final Release**
- Integration testleri
- End-to-end testler
- Final release: `v1.1.0` (production tag)

---

## ğŸ”§ Utility Scripts

### P1 Test Script

**`scripts/test_p1_risky_scenarios.sh`** (oluÅŸturulacak):

```bash
#!/bin/bash
# P1 Risky Scenario Test Suite

set -e

echo "ğŸ§ª Running P1 Risky Scenario Tests..."

# 1. Alembic Migration Tests
echo "ğŸ“¦ Testing Alembic Migration..."
docker-compose exec api alembic upgrade head
docker-compose exec api alembic downgrade -1
docker-compose exec api alembic upgrade head
docker-compose exec api alembic --autogenerate --dry-run

# 2. Distributed Rate Limiting Tests
echo "ğŸš¦ Testing Distributed Rate Limiting..."
docker-compose stop redis
docker-compose exec api pytest tests/test_rate_limiter.py::test_redis_down_fallback -v
docker-compose start redis

# 3. Caching Layer Tests
echo "ğŸ’¾ Testing Caching Layer..."
docker-compose exec api pytest tests/test_cache.py -v

# 4. Bulk Operations Tests
echo "ğŸ“¦ Testing Bulk Operations..."
docker-compose exec api pytest tests/test_bulk_operations.py -v

# 5. API Versioning Tests
echo "ğŸ”€ Testing API Versioning..."
docker-compose exec api pytest tests/test_api_versioning.py -v

echo "âœ… All P1 risky scenario tests passed!"
```

### P1 Smoke Test Script

**`scripts/smoke_test_p1.sh`** (oluÅŸturulacak):

```bash
#!/bin/bash
# P1 Smoke Test Suite

set -e

echo "ğŸ’¨ Running P1 Smoke Tests..."

# 1. Health Check
echo "ğŸ¥ Health Check..."
curl -f http://localhost:8000/healthz || exit 1

# 2. Redis Health (DRL iÃ§in)
echo "ğŸ”´ Redis Health..."
curl -f http://localhost:8000/healthz/ready || exit 1

# 3. API Endpoints (Versioning iÃ§in)
echo "ğŸ”€ API Endpoints..."
curl -f "http://localhost:8000/leads?segment=Migration" || exit 1
curl -f "http://localhost:8000/api/v1/leads?segment=Migration" || exit 1

# 4. Cache Hit Rate (Caching iÃ§in)
echo "ğŸ’¾ Cache Hit Rate..."
# Cache hit rate metric kontrolÃ¼

# 5. Bulk Scan (Bulk Operations iÃ§in)
echo "ğŸ“¦ Bulk Scan..."
JOB_ID=$(curl -s -X POST http://localhost:8000/scan/bulk \
  -H "Content-Type: application/json" \
  -d '{"domain_list": ["example.com"]}' | jq -r '.job_id')
curl -f "http://localhost:8000/scan/bulk/$JOB_ID" || exit 1

echo "âœ… All P1 smoke tests passed!"
```

---

## ğŸ“š Referanslar

- **P1 Priority Document**: `docs/active/KALAN-ISLER-PRIORITY.md`
- **Commit Checklist**: `COMMIT_CHECKLIST.md`
- **Commands Reference**: `.cursor/commands/commands.md`
- **Development Environment**: `docs/active/DEVELOPMENT-ENVIRONMENT.md`
- **Cursor Rules**: `.cursor/rules/.cursorrules`

---

**Son GÃ¼ncelleme**: 2025-01-28  
**Durum**: âœ… **P1 TamamlandÄ± (2025-01-28)** - Reference Guide  
**Not**: P1 maddeleri tamamlandÄ±. Bu playbook artÄ±k reference guide olarak kullanÄ±labilir (test komutlarÄ±, rollback reÃ§eteleri, risky scenario simulasyonlarÄ± gelecekteki benzer iÅŸler iÃ§in referans olarak deÄŸerli).

