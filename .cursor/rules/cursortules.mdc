---
alwaysApply: true
# Dyn365Hunter MVP - Cursor Rules

## Project Context
- **MVP Scope**: FastAPI + PostgreSQL, rule-based scoring, DNS/WHOIS analysis
- **Target**: ‚â§2 minute "kahvelik" analysis flow for sales team
- **MVP Status**: ‚úÖ Completed (G1-G14)
- **Post-MVP Sprint 1-5 (G14-G18)**: ‚úÖ Completed
- **Post-MVP Sprint 6 (G19)**: üìã Planned - Auth + UI + Advanced Features
- **Out of Scope**: D365 adapter, `scripts/demo_run.sh`

## Code Style & Standards

### Python
- Use type hints for all functions
- Follow PEP 8 (black formatter preferred)
- Use f-strings for string formatting
- Prefer explicit over implicit (no magic numbers/strings)
- Use `app/core/constants.py` for business logic thresholds (scores, expiry days, bulk limits)

### FastAPI
- Use Pydantic models for request/response validation
- Use dependency injection for DB sessions (`get_db()`)
- Return proper HTTP status codes (201 Created, 400 Bad Request, 404 Not Found, 500 Internal Server Error)
- Use async/await only if needed (DB I/O can be sync for MVP)

### Database
- Use SQLAlchemy ORM (no raw SQL except in schema.sql)
- Domain is UNIQUE key in `companies` table
- Use idempotent upsert for companies (ON CONFLICT DO UPDATE)
- Always use transactions for multi-step operations

### Error Handling
- DNS timeout: 10s max, return None/error status, set `scan_status='dns_timeout'`
- WHOIS timeout: 5s max, graceful fail (return None), set `scan_status='whois_failed'`
- Invalid domain: Return 400 Bad Request with clear error message
- Never crash on external API failures (DNS/WHOIS) - continue with partial data

### Logging & PII
- **CRITICAL**: Log only domain, NEVER log email or company_name
- Use structured logging (JSON format preferred)
- Log level: INFO for normal operations, ERROR for failures, DEBUG for development

### Testing
- Write tests for all core functions (normalizer, analyzer, scorer)
- Test edge cases: invalid domains, timeouts, malformed CSV, missing MX records
- Use pytest with pytest-mock for mocking DNS/WHOIS
- Target: ‚â•70% code coverage for core modules

## MVP Scope Discipline

### ‚úÖ IN SCOPE
- Health check (`GET /healthz`) - Database connection status
- Single domain ingestion (`POST /ingest/domain`)
- CSV/Excel ingestion (`POST /ingest/csv`) - parse + normalize + insert + optional auto-scan
  - CSV support (.csv)
  - Excel support (.xlsx, .xls)
  - Auto-detect columns (`auto_detect_columns` query parameter) for OSB Excel files
  - Auto-scan (`auto_scan=true` query parameter) - Automatically scan domains after ingestion
  - Progress tracking - Real-time job progress updates via `/jobs/{job_id}`
- Single domain scan (`POST /scan/domain`) - DNS + WHOIS + scoring
  - Provider change detection and logging
  - Duplicate prevention (delete old records before creating new ones)
- Leads query (`GET /leads` with filters)
- Single lead query (`GET /leads/{domain}`)
- Dashboard endpoint (`GET /dashboard`) - Aggregated statistics
- Priority Score feature - Lead prioritization (1-6 scale)
- Email generation (`POST /email/generate`) - Generic email addresses for domains
- Email validation (`POST /email/generate-and-validate`) - Syntax, MX, optional SMTP validation
- **Mini UI** (`/mini-ui/`) - Simple web interface for demo and internal use (API_BASE_URL configurable via `window.HUNTER_API_BASE_URL`)
- **CSV/Excel export** (`GET /leads/export`) - Export leads with filters
- **Provider change tracking** - Automatic detection and history logging
- **Duplicate prevention** - Automatic cleanup of duplicate records
- **Domain validation** - Enhanced validation to filter invalid domains
- **Bulk scan** (`POST /scan/bulk`) - Async bulk domain scanning with Celery + Redis
- **Webhook ingestion** (`POST /ingest/webhook`) - API key authenticated webhook endpoint
- **Lead enrichment** - Contact emails, quality score, LinkedIn pattern detection
- **Notes/Tags/Favorites** - CRM-lite features with session-based favorites
- **PDF summaries** (`GET /leads/{domain}/summary.pdf`) - Account summary PDF generation
- **ReScan infrastructure** (`POST /scan/{domain}/rescan`, `POST /scan/bulk/rescan`) - Manual and bulk rescan with change detection
- **Alerts system** (`GET /alerts`, `POST /alerts/config`) - Change alerts (MX, DMARC, expiry, score)
- **Enhanced scoring** - Signal-based improvements (DKIM none penalty, SPF multiple includes risk)
- Docker Compose setup
- Basic tests (8+ test files)

### ‚ùå OUT OF SCOPE (Post-MVP - Sprint 6'da planlandƒ±)
- **Sprint 6 (G19)**: Auth + UI + Advanced Features - üìã Planlandƒ±
- **Still Out of Scope**: D365 adapter, `scripts/demo_run.sh`
- **Note**: Redis/Queue ve Scheduler Sprint 2-5'te eklendi (Celery + Redis)

## File Structure Rules

### Required Files (P0)
- `Dockerfile`, `docker-compose.yml`, `.dockerignore`
- `setup_dev.sh` (one-command setup)
- `.env.example` (all required env vars)
- `requirements.txt` (pinned versions)
- `app/main.py` (FastAPI app + `/healthz`)
- `app/config.py` (Pydantic Settings with `HUNTER_` prefix - use `HUNTER_DATABASE_URL`, `HUNTER_REDIS_URL`, etc.)
- `app/db/schema.sql` (PostgreSQL DDL)
- `app/db/models.py` (SQLAlchemy models)
- `app/db/session.py` (DB session factory)
- `app/core/normalizer.py` (includes `is_valid_domain()`), `analyzer_dns.py`, `analyzer_whois.py`, `provider_map.py`, `scorer.py`, `merger.py`, `priority.py`, `importer.py`, `email_generator.py`, `email_validator.py`, `constants.py`, `change_detection.py`, `rescan.py`, `auto_tagging.py`, `notifications.py`
- `app/api/ingest.py`, `scan.py`, `leads.py`, `dashboard.py`, `email_tools.py`, `progress.py`, `jobs.py`, `bulk_scan.py`, `rescan.py`, `webhook.py`, `export.py`, `notes.py`, `tags.py`, `favorites.py`, `pdf.py`, `alerts.py`
- `app/data/providers.json`, `rules.json`
- `tests/test_scan_single.py`, `test_scorer_rules.py`, `test_ingest_csv.py`, `test_api_endpoints.py`, `test_priority.py`, `test_importer_autodetect.py`, `test_email_generator.py`, `test_email_validator.py`
- `README.md`

### File Naming
- Use snake_case for Python files
- Use kebab-case for shell scripts (`setup_dev.sh`)
- Use lowercase for JSON config files (`providers.json`, `rules.json`)

## Implementation Priorities

### P0 (Must Have)
- Docker setup, DB schema, FastAPI skeleton
- Health check endpoint (`/healthz`)
- Domain normalization, ingestion endpoints
- DNS/WHOIS analyzers, provider mapping, scoring
- Scan endpoint, leads API, dashboard endpoint
- Priority score calculation
- Basic tests, README

### P1 (Should Have)
- Edge case tests, error handling improvements
- Healthcheck improvements, logging enhancements

### P2 (Nice to Have)
- Performance optimizations, additional test coverage

## Performance Targets
- Single domain scan: ‚â§10s (cold: ‚â§15s acceptable)
- API response: <1s for `/leads` query
- CSV/Excel ingestion: Parse + normalize + insert only (scan separate)
- Email generation: <1s response time
- Email validation (light): <1s response time (syntax + MX only)
- Email validation (full): 10-30s response time (with SMTP check)

## Data Files

### providers.json
- Must contain 10+ providers (M365, Google, Yandex, Hosting, Local, Unknown)
- Include MX root examples for each provider
- Format: `{"providers": [{"name": "M365", "mx_roots": ["outlook.com", "protection.outlook.com"], ...}]}`

### rules.json
- Must contain: `base_score`, `provider_points`, `signal_points`, `segment_rules`
- Segment rules order matters (evaluate top to bottom)
- Format: `{"base_score": 0, "provider_points": {"M365": 50, ...}, "signal_points": {"spf": 10, ...}, "segment_rules": [...]}`

## Docker & Development

### Docker Compose
- PostgreSQL 15-alpine with healthcheck
- FastAPI service with healthcheck
- Use `depends_on.condition: service_healthy` (not just `depends_on`)
- Volume mounts for hot-reload: `./app:/app/app`

### setup_dev.sh
- Check Docker/Docker Compose availability
- Copy `.env.example` to `.env` if not exists
- `docker-compose up -d`
- Wait for PostgreSQL healthcheck (max 30s)
- Run schema migration automatically (Python script or Alembic, NOT manual docker-compose exec)
- Verify `/healthz` endpoint
- Print access URLs

## Code Review Checklist

Before marking code as done, verify:
- [ ] Type hints added
- [ ] Error handling implemented (timeouts, invalid input)
- [ ] No PII in logs (domain only)
- [ ] Tests written for new functions
- [ ] MVP scope respected (Post-MVP features: bulk, webhook, export, rescan, alerts are now in scope)
- [ ] Docker Compose still works
- [ ] `/healthz` still responds

## Common Patterns

### Domain Normalization
```python
def normalize_domain(domain: str) -> str:
    # Extract domain from URL if needed
    # punycode decode, strip www, lowercase
    # validate domain format
    # return normalized domain or empty string if invalid

def is_valid_domain(domain: str) -> bool:
    # Check for invalid values (nan, web sitesi, etc.)
    # Validate domain format (dots, TLD, character rules)
    # return True if valid, False otherwise
```

### DNS Analysis
```python
def analyze_dns(domain: str) -> Dict[str, Any]:
    # timeout: 10s
    # return: {"mx_root": str, "spf": bool, "dkim": bool, "dmarc_policy": str}
    # on timeout: return None, set scan_status='dns_timeout'
```

### WHOIS Analysis
```python
def get_whois_info(domain: str) -> Optional[Dict[str, Any]]:
    # timeout: 5s
    # return: {"registrar": str, "expires_at": datetime, "nameservers": List[str]}
    # on fail: return None, set scan_status='whois_failed', continue scoring
```

### Scoring
```python
def score_domain(domain: str, signals: Dict, provider: str, mx_records: List[str]) -> Dict[str, Any]:
    # validate domain first
    # check hard-fail rules (e.g., missing MX)
    # load rules.json
    # calculate base_score + provider_points + signal_points - risk_points
    # determine segment (order matters)
    # return: {"score": int, "segment": str, "reason": str}
```

### Email Generation
```python
def generate_generic_emails(domain: str) -> List[str]:
    # normalize domain
    # generate emails from GENERIC_LOCAL_PARTS list
    # return sorted unique list of emails
```

### Email Validation
```python
def validate_email(email: str, use_smtp: bool = False) -> EmailValidationResult:
    # syntax check (regex)
    # MX check (DNS)
    # optional SMTP check (if use_smtp=True)
    # return EmailValidationResult with status, confidence, checks
```

## Documentation Management

### ‚ö†Ô∏è AUTOMATIC DOCUMENTATION UPDATES (ALWAYS ACTIVE)
**IMPORTANT**: When you create/modify code, ALWAYS update documentation automatically:

1. **New API endpoints** (`app/api/*.py`) ‚Üí Update README.md API Endpoints section
2. **New test files** (`tests/*.py`) ‚Üí Update CHANGELOG.md under "Added" ‚Üí "G9: Tests"
3. **New core modules** (`app/core/*.py`) ‚Üí Update CHANGELOG.md with module description
4. **Phase completion** (TODO status = "Completed") ‚Üí Run full phase completion workflow

**DO NOT WAIT** for user to ask - update documentation immediately after code changes.

### Phase Completion Workflow
When a phase is completed (TODO status = "Completed"):
1. **Archive TODO**: `scripts/manage_docs.sh phase-complete <phase> <name>`
2. **Update CHANGELOG.md**: Add phase changes under `[Unreleased]` ‚Üí `### Added`
3. **Update README.md**: Mark completed features in Features section
4. **Update docs/README.md**: Add phase to "Archived Documentation" section
5. **Archive related docs**: Move phase-specific docs from `docs/active/` to `docs/archive/`

### Documentation Structure
- `docs/active/` - Current phase documentation (keep minimal, max 5-7 files)
- `docs/archive/` - Completed phase documentation (date-prefixed)
- `docs/prompts/` - Important prompts (date-prefixed, archive when done)
- `docs/todos/` - TODO lists (archive when phase complete)
- `docs/plans/` - Project plans

### When to Archive
- Phase complete ‚Üí Run phase completion workflow (see above)
- Prompt no longer referenced ‚Üí Archive prompt
- Keep only active/current documentation visible

## Questions to Ask Before Implementing

1. Is this in MVP scope? (Check Cut List)
2. **Is this in the correct Post-MVP sprint?** (Check `docs/plans/2025-11-14-FINAL-ROADMAP.md`)
3. Does this require external API calls? (Handle timeouts/errors)
4. Will this log PII? (Only log domain)
5. Is this testable? (Write tests)
6. Does this break Docker setup? (Verify setup_dev.sh still works)
7. **Did I update documentation?** (CHANGELOG.md, README.md, docs/README.md when phase completes)
8. **Am I implementing features in the wrong sprint?** (Check roadmap for correct sprint assignment)


---
