---
alwaysApply: true
# Dyn365Hunter MVP - Cursor Rules

## Project Context
- **MVP Scope**: FastAPI + PostgreSQL, rule-based scoring, DNS/WHOIS analysis
- **Target**: ‚â§2 minute "kahvelik" analysis flow for sales team
- **MVP Status**: ‚úÖ Completed (G1-G14)
- **Post-MVP Sprint 1-5 (G14-G18)**: ‚úÖ Completed
- **Post-MVP Sprint 6 (G19)**: ‚úÖ Completed - Auth + UI + Advanced Features
- **P0 Hardening (G19)**: ‚úÖ Completed - DB Connection Pooling, API Key Security, Structured Logging, Error Tracking, Health Checks
- **P1 Performance**: ‚úÖ Completed (2025-01-28) - Alembic Migration, Distributed Rate Limiting, Caching Layer, Bulk Operations, API Versioning
- **‚úÖ Stabilization Sprint**: ‚úÖ Completed (2025-01-28) - v1.1-stable (Enterprise-Ready / UI-Stable / Integration-Ready)
- **‚úÖ CSP P-Model Integration**: ‚úÖ Completed (2025-01-29) - Production v1.1 Core Feature - Global CSP Priority Model (P1-P6), Commercial Segment & Heat, Technical Heat, Priority Category & Label, UI integration (P-badges, tooltips, score breakdown panel)
- **‚úÖ Production Bug Fixes**: ‚úÖ Completed (2025-01-29) - DMARC Coverage bug fix, Risk Summary text fix, Score Modal provider-specific description
- **üîÑ G21: Architecture Refactor**: üîÑ In Progress (2025-01-28) - Hunter Slimming to Core Signal Engine
- **Out of Scope**: D365 adapter, `scripts/demo_run.sh`

## Code Style & Standards

### Python
- Use type hints for all functions
- Follow PEP 8 (black formatter preferred)
- Use f-strings for string formatting
- Prefer explicit over implicit (no magic numbers/strings)
- Use `app/core/constants.py` for business logic thresholds (scores, expiry days, bulk limits)

### FastAPI
- Use Pydantic models for request/response validation
- Use dependency injection for DB sessions (`get_db()`)
- Return proper HTTP status codes (201 Created, 400 Bad Request, 404 Not Found, 500 Internal Server Error)
- Use async/await only if needed (DB I/O can be sync for MVP)

### Database
- Use SQLAlchemy ORM (no raw SQL except in schema.sql)
- Domain is UNIQUE key in `companies` table
- Use idempotent upsert for companies (ON CONFLICT DO UPDATE)
- Always use transactions for multi-step operations

### Error Handling
- DNS timeout: 10s max, return None/error status, set `scan_status='dns_timeout'`
- WHOIS timeout: 5s max, graceful fail (return None), set `scan_status='whois_failed'`
- Invalid domain: Return 400 Bad Request with clear error message
- Never crash on external API failures (DNS/WHOIS) - continue with partial data

### Logging & PII
- **CRITICAL**: Log only domain, NEVER log email or company_name
- Use structured logging (JSON format preferred)
- Log level: INFO for normal operations, ERROR for failures, DEBUG for development

### Testing
- Write tests for all core functions (normalizer, analyzer, scorer)
- Test edge cases: invalid domains, timeouts, malformed CSV, missing MX records
- Use pytest with pytest-mock for mocking DNS/WHOIS
- Target: ‚â•70% code coverage for core modules
- **Test Suite**: 497 tests with transaction-based isolation
- **Shared Fixtures**: Use `tests/conftest.py` fixtures (`db_session`, `client`) for consistent test isolation
- **Test Isolation**: Each test runs in isolated transaction with automatic rollback
- **Integration Tests**: Use `@pytest.mark.requires_integration` for Redis/Celery-dependent tests
- **All tests must pass**: 497 tests (CI/CD enforced)

## MVP Scope Discipline

### ‚úÖ IN SCOPE
- Health check (`GET /healthz`) - Database connection status
- Single domain ingestion (`POST /ingest/domain`)
- CSV/Excel ingestion (`POST /ingest/csv`) - parse + normalize + insert + optional auto-scan
  - CSV support (.csv)
  - Excel support (.xlsx, .xls)
  - Auto-detect columns (`auto_detect_columns` query parameter) for OSB Excel files
  - Auto-scan (`auto_scan=true` query parameter) - Automatically scan domains after ingestion
  - Progress tracking - Real-time job progress updates via `/jobs/{job_id}`
- Single domain scan (`POST /scan/domain`) - DNS + WHOIS + scoring
  - Provider change detection and logging
  - Duplicate prevention (delete old records before creating new ones)
- Leads query (`GET /leads` with filters)
- Single lead query (`GET /leads/{domain}`)
- Dashboard endpoint (`GET /dashboard`) - Aggregated statistics
- Priority Score feature - Lead prioritization (1-6 scale)
- Email generation (`POST /email/generate`) - Generic email addresses for domains
- Email validation (`POST /email/generate-and-validate`) - Syntax, MX, optional SMTP validation
- **Mini UI** (`/mini-ui/`) - Simple web interface for demo and internal use (API_BASE_URL configurable via `window.HUNTER_API_BASE_URL`)
  - **Phase 3 (2025-01-29)**: CSP P-Model Integration - P1-P6 badges, tooltips, score breakdown panel, provider-specific descriptions
  - **12+ features**: Upload, Scan, Table, Export, Search, Sorting, Pagination, Score Breakdown, Toast Notifications, Tooltips, P-Model Badges, CSP P-Model Panel
- **CSV/Excel export** (`GET /leads/export`) - Export leads with filters
- **Provider change tracking** - Automatic detection and history logging
- **Duplicate prevention** - Automatic cleanup of duplicate records
- **Domain validation** - Enhanced validation to filter invalid domains
- **Bulk scan** (`POST /scan/bulk`) - Async bulk domain scanning with Celery + Redis
- **Webhook ingestion** (`POST /ingest/webhook`) - API key authenticated webhook endpoint
- **Lead enrichment** - Contact emails, quality score, LinkedIn pattern detection
- **Notes/Tags/Favorites** - CRM-lite features with session-based favorites
- **PDF summaries** (`GET /leads/{domain}/summary.pdf`) - Account summary PDF generation
- **ReScan infrastructure** (`POST /scan/{domain}/rescan`, `POST /scan/bulk/rescan`) - Manual and bulk rescan with change detection
- **Alerts system** (`GET /alerts`, `POST /alerts/config`) - Change alerts (MX, DMARC, expiry, score)
- **Enhanced scoring** - Signal-based improvements (DKIM none penalty, SPF multiple includes risk)
- **IP Enrichment** - IP geolocation, ASN, ISP, and proxy detection (MaxMind, IP2Location, IP2Proxy) with simplified env format (`MAXMIND_CITY_DB`, `MAXMIND_COUNTRY_DB`, `IP2LOCATION_DB`, `IP2PROXY_DB`)
- Docker Compose setup
- Basic tests (8+ test files)

### ‚ùå OUT OF SCOPE (Post-MVP - Sprint 6'da planlandƒ±)
- **Sprint 6 (G19)**: Auth + UI + Advanced Features - üìã Planlandƒ±
- **Still Out of Scope**: D365 adapter, `scripts/demo_run.sh`
- **Note**: Redis/Queue ve Scheduler Sprint 2-5'te eklendi (Celery + Redis)

## File Structure Rules

### Required Files (P0)
- `Dockerfile`, `docker-compose.yml`, `.dockerignore`
- `setup_dev.sh` (one-command setup)
- `.env.example` (all required env vars)
- `requirements.txt` (pinned versions)
- `app/main.py` (FastAPI app + `/healthz`)
- `app/config.py` (Pydantic Settings with `HUNTER_` prefix - use `HUNTER_DATABASE_URL`, `HUNTER_REDIS_URL`, etc.)
- `app/db/schema.sql` (PostgreSQL DDL)
- `app/db/models.py` (SQLAlchemy models)
- `app/db/session.py` (DB session factory)
- `app/core/normalizer.py` (includes `is_valid_domain()`), `analyzer_dns.py`, `analyzer_whois.py`, `provider_map.py`, `scorer.py`, `merger.py`, `priority.py`, `importer.py`, `email_generator.py`, `email_validator.py`, `constants.py`, `change_detection.py`, `rescan.py`, `auto_tagging.py`, `notifications.py`
- `app/api/ingest.py`, `scan.py`, `leads.py`, `dashboard.py`, `email_tools.py`, `progress.py`, `jobs.py`, `bulk_scan.py`, `rescan.py`, `webhook.py`, `export.py`, `notes.py`, `tags.py`, `favorites.py`, `pdf.py`, `alerts.py`
- `app/data/providers.json`, `rules.json`
- `tests/test_scan_single.py`, `test_scorer_rules.py`, `test_ingest_csv.py`, `test_api_endpoints.py`, `test_priority.py`, `test_importer_autodetect.py`, `test_email_generator.py`, `test_email_validator.py`
- `README.md`

### File Naming
- Use snake_case for Python files
- Use kebab-case for shell scripts (`setup_dev.sh`)
- Use lowercase for JSON config files (`providers.json`, `rules.json`)

## Implementation Priorities

### P0 (Must Have)
- Docker setup, DB schema, FastAPI skeleton
- Health check endpoint (`/healthz`)
- Domain normalization, ingestion endpoints
- DNS/WHOIS analyzers, provider mapping, scoring
- Scan endpoint, leads API, dashboard endpoint
- Priority score calculation
- Basic tests, README

### P1 (Should Have - Performance & Infrastructure) ‚úÖ Completed (2025-01-28)
- ‚úÖ **Alembic Migration System** - Migration history tracking, rollback capability, schema drift detection
- ‚úÖ **Distributed Rate Limiting** - Redis-based rate limiting for multi-worker deployments
- ‚úÖ **Caching Layer** - Redis-based distributed caching (DNS, WHOIS, Provider, Scoring, Scan)
- ‚úÖ **Bulk Operations Optimization** - Batch processing, deadlock prevention, partial commit recovery
- ‚úÖ **API Versioning** - `/api/v1/` structure with backward compatibility
- **Reference**: `docs/active/P1-IMPLEMENTATION-PLAYBOOK.md` (completed, now reference guide)

### P2 (Nice to Have)
- Performance optimizations, additional test coverage

## Performance Targets
- Single domain scan: ‚â§10s (cold: ‚â§15s acceptable)
- API response: <1s for `/leads` query
- CSV/Excel ingestion: Parse + normalize + insert only (scan separate)
- Email generation: <1s response time
- Email validation (light): <1s response time (syntax + MX only)
- Email validation (full): 10-30s response time (with SMTP check)

## Data Files

### providers.json
- Must contain 10+ providers (M365, Google, Yandex, Hosting, Local, Unknown)
- Include MX root examples for each provider
- Format: `{"providers": [{"name": "M365", "mx_roots": ["outlook.com", "protection.outlook.com"], ...}]}`

### rules.json
- Must contain: `base_score`, `provider_points`, `signal_points`, `segment_rules`
- Segment rules order matters (evaluate top to bottom)
- Format: `{"base_score": 0, "provider_points": {"M365": 50, ...}, "signal_points": {"spf": 10, ...}, "segment_rules": [...]}`

## Docker & Development

### Docker Compose
- PostgreSQL 15-alpine with healthcheck
- FastAPI service with healthcheck
- Use `depends_on.condition: service_healthy` (not just `depends_on`)
- Volume mounts for hot-reload: `./app:/app/app`

### setup_dev.sh
- Check Docker/Docker Compose availability
- Copy `.env.example` to `.env` if not exists
- `docker-compose up -d`
- Wait for PostgreSQL healthcheck (max 30s)
- Run schema migration automatically (Python script or Alembic, NOT manual docker-compose exec)
- Verify `/healthz` endpoint
- Print access URLs

## Code Review Checklist

Before marking code as done, verify:
- [ ] Type hints added
- [ ] Error handling implemented (timeouts, invalid input)
- [ ] No PII in logs (domain only)
- [ ] Tests written for new functions
- [ ] MVP scope respected (Post-MVP features: bulk, webhook, export, rescan, alerts are now in scope)
- [ ] Docker Compose still works
- [ ] `/healthz` still responds

## Common Patterns

### Domain Normalization
```python
def normalize_domain(domain: str) -> str:
    # Extract domain from URL if needed
    # punycode decode, strip www, lowercase
    # validate domain format
    # return normalized domain or empty string if invalid

def is_valid_domain(domain: str) -> bool:
    # Check for invalid values (nan, web sitesi, etc.)
    # Validate domain format (dots, TLD, character rules)
    # return True if valid, False otherwise
```

### DNS Analysis
```python
def analyze_dns(domain: str) -> Dict[str, Any]:
    # timeout: 10s
    # return: {"mx_root": str, "spf": bool, "dkim": bool, "dmarc_policy": str}
    # on timeout: return None, set scan_status='dns_timeout'
```

### WHOIS Analysis
```python
def get_whois_info(domain: str) -> Optional[Dict[str, Any]]:
    # timeout: 5s
    # return: {"registrar": str, "expires_at": datetime, "nameservers": List[str]}
    # on fail: return None, set scan_status='whois_failed', continue scoring
```

### Scoring
```python
def score_domain(domain: str, signals: Dict, provider: str, mx_records: List[str]) -> Dict[str, Any]:
    # validate domain first
    # check hard-fail rules (e.g., missing MX)
    # load rules.json
    # calculate base_score + provider_points + signal_points - risk_points
    # determine segment (order matters)
    # return: {"score": int, "segment": str, "reason": str}
```

### Email Generation
```python
def generate_generic_emails(domain: str) -> List[str]:
    # normalize domain
    # generate emails from GENERIC_LOCAL_PARTS list
    # return sorted unique list of emails
```

### Email Validation
```python
def validate_email(email: str, use_smtp: bool = False) -> EmailValidationResult:
    # syntax check (regex)
    # MX check (DNS)
    # optional SMTP check (if use_smtp=True)
    # return EmailValidationResult with status, confidence, checks
```

## Documentation Management

### ‚ö†Ô∏è AUTOMATIC DOCUMENTATION UPDATES (ALWAYS ACTIVE)
**IMPORTANT**: When you create/modify code, ALWAYS update documentation automatically:

1. **New API endpoints** (`app/api/*.py`) ‚Üí Update README.md API Endpoints section
2. **New test files** (`tests/*.py`) ‚Üí Update CHANGELOG.md under "Added" ‚Üí "G9: Tests"
3. **New core modules** (`app/core/*.py`) ‚Üí Update CHANGELOG.md with module description
4. **Phase completion** (TODO status = "Completed") ‚Üí Run full phase completion workflow

**DO NOT WAIT** for user to ask - update documentation immediately after code changes.

### Phase Completion Workflow
When a phase is completed (TODO status = "Completed"):
1. **Archive TODO**: `scripts/manage_docs.sh phase-complete <phase> <name>`
2. **Update CHANGELOG.md**: Add phase changes under `[Unreleased]` ‚Üí `### Added`
3. **Update README.md**: Mark completed features in Features section
4. **Update docs/README.md**: Add phase to "Archived Documentation" section
5. **Archive related docs**: Move phase-specific docs from `docs/active/` to `docs/archive/`

### Documentation Structure
- `docs/active/` - Current phase documentation (keep minimal, max 5-7 files)
- `docs/archive/` - Completed phase documentation (date-prefixed)
- `docs/prompts/` - Important prompts (date-prefixed, archive when done)
- `docs/todos/` - TODO lists (archive when phase complete)
- `docs/plans/` - Project plans

### When to Archive
- Phase complete ‚Üí Run phase completion workflow (see above)
- Prompt no longer referenced ‚Üí Archive prompt
- Keep only active/current documentation visible

## Guardrails & Validation Rules

### Test Suite Guardrails
- **Test Count**: 497 tests (must maintain or increase)
- **Test Isolation**: Always use `db_session` fixture from `tests/conftest.py` for transaction-based isolation
- **Test Client**: Always use `client` fixture from `tests/conftest.py` for API tests
- **Integration Tests**: Use `@pytest.mark.requires_integration` and `redis_and_celery_available` fixture
- **Test Coverage**: ‚â•70% for core modules (`app/core/`)
- **All tests must pass**: CI/CD enforces all 497 tests passing before merge

### Documentation Guardrails
- **Active Docs Limit**: Maximum 5-7 files in `docs/active/`
- **Archive Immediately**: Archive completed phase docs immediately (don't wait)
- **Date Prefix**: All archived files must have `YYYY-MM-DD-` prefix
- **Auto-Update**: Always update README.md, CHANGELOG.md, docs/README.md when code changes
- **Token Efficiency**: Don't repeat archived information, reference when needed

### Code Quality Guardrails
- **Type Hints**: Required for all functions
- **Black Formatting**: Enforced in CI (`.github/workflows/lint.yml`)
- **Flake8 Linting**: Max line length 127, complexity ‚â§10
- **Type Checking**: mypy (non-blocking, ignore missing imports)
- **No Magic Numbers**: Use `app/core/constants.py` for all thresholds
- **No PII in Logs**: Only log domain, NEVER log email or company_name

### Security Guardrails
- **API Keys**: Store hashed (SHA-256), never plaintext
- **PII Protection**: Never log email, company_name, or other PII
- **Environment Variables**: Always use `HUNTER_` prefix
- **Rate Limiting**: Always enforce rate limits (DNS: 10 req/s, WHOIS: 5 req/s)
- **Input Validation**: Validate all user inputs (domains, API keys, etc.)

### Performance Guardrails
- **Bulk Limits**: Maximum 1000 domains per bulk operation
- **Timeouts**: DNS (10s), WHOIS (5s), RDAP (3s), SMTP (3s), Celery (900s)
- **Rate Limiting**: Always use in bulk operations and Celery tasks
- **Caching**: Use Redis caching for DNS, WHOIS, Provider, Scoring (when available)

### API Contract Guardrails (G21)
- **Frozen Contracts**: Sales Summary API v1 contract is frozen (no breaking changes)
- **Read-Only Mode**: Write endpoints return 410 Gone (Phase 3)
- **Backward Compatibility**: Legacy endpoints remain available during migration
- **Deprecation Monitoring**: Track deprecated endpoint usage via `/healthz/metrics`

### Database Migration & Reset Guardrails (CRITICAL - Lessons Learned 2025-01-29)
- **‚ö†Ô∏è schema.sql DEPRECATED**: `app/db/schema.sql` is **OUTDATED** and **MUST NOT** be used for database reset
  - **Reason**: Missing G20 columns (`tenant_size`, `local_provider`, `dmarc_coverage`) and CSP P-Model columns
  - **Impact**: Causes schema mismatches, missing columns, view errors, API failures
  - **Official Way**: Use `./scripts/reset_db_with_alembic.sh` or `Base.metadata.create_all()` + Alembic stamp
- **‚ö†Ô∏è Legacy SQL Migrations DEPRECATED**: `app/db/migrations/legacy/*.sql` files are **ARCHIVED** and **MUST NOT** be used
  - **Reason**: Transaction-unsafe, can fail mid-execution, out of sync with Alembic migrations
  - **Location**: Moved to `docs/archive/legacy-migrations/` (historical reference only)
  - **Official Way**: All schema changes must use Alembic migrations (`alembic/versions/`)
- **Database Reset Policy** (MANDATORY):
  - ‚ùå **DO NOT**: Use `schema.sql` or legacy SQL migrations for database reset
  - ‚ùå **DO NOT**: Combine `schema.sql` with legacy migrations (causes schema mismatches)
  - ‚úÖ **DO**: Use `./scripts/reset_db_with_alembic.sh` for database reset (official script)
  - ‚úÖ **DO**: Use `Base.metadata.create_all()` + Alembic stamp for fresh database setup
  - ‚úÖ **DO**: Always use Alembic migrations (`alembic upgrade head`) for schema changes
  - ‚úÖ **DO**: Verify critical columns after reset (`tenant_size`, `local_provider`, `dmarc_coverage`, P-Model columns)
- **Base Revision Migration Issues**:
  - Base revision (`08f51db8dce0_base_revision.py`) assumes tables exist (ALTER operations)
  - **Fix**: Use `Base.metadata.create_all()` first, then stamp base revision as applied
  - **Pattern**: Create tables from models ‚Üí Stamp migrations ‚Üí Run remaining migrations
- **API SQL Query Guardrails**:
  - ‚ùå **DO NOT**: SELECT columns that may not exist in view (`tenant_size`, `local_provider`, `dmarc_coverage`)
  - ‚úÖ **DO**: Use dynamic column checking or `getattr()` when reading from view
  - ‚úÖ **DO**: Verify view columns exist before using in SQL queries
  - **Example**: `leads_ready` view may not have all columns depending on migration state
- **leads_ready View Maintenance**:
  - View must include P-Model columns (`technical_heat`, `commercial_segment`, `commercial_heat`, `priority_category`, `priority_label`)
  - View must be updated when new columns are added to `lead_scores` table
  - CSP P-Model migration (`f786f93501ea`) handles view update dynamically
- **Migration Verification** (After Reset):
  - Verify `companies.tenant_size` exists (G20 column)
  - Verify `domain_signals.local_provider` and `domain_signals.dmarc_coverage` exist (G20 columns)
  - Verify `lead_scores` P-Model columns exist (`technical_heat`, `commercial_segment`, `commercial_heat`, `priority_category`, `priority_label`)
  - Verify `leads_ready` view has all expected columns
- **Reference Documentation**:
  - `docs/reference/PRODUCTION-DEPLOYMENT-GUIDE.md` - Migration Flow section (reset policy)
  - `docs/reference/TROUBLESHOOTING-GUIDE.md` - Database Reset Issues section
  - `docs/archive/legacy-migrations/README.md` - Why legacy migrations are deprecated

## Questions to Ask Before Implementing

1. Is this in MVP scope? (Check Cut List)
2. **Is this in the correct Post-MVP sprint?** (Check `docs/plans/2025-11-14-FINAL-ROADMAP.md`)
3. **Is this a P1 performance/infrastructure task?** (‚úÖ Completed - 2025-01-28 - Check `docs/active/KALAN-ISLER-PRIORITY.md`)
4. **Is this a Stabilization Sprint task?** (‚úÖ Completed - 2025-01-28 - v1.1-stable released)
5. **Is this a G21 Architecture Refactor task?** (üîÑ In Progress - 2025-01-28 - Check `docs/active/NO-BREAK-REFACTOR-PLAN.md`)
6. Does this require external API calls? (Handle timeouts/errors)
7. Will this log PII? (Only log domain)
8. Is this testable? (Write tests using `db_session` and `client` fixtures)
9. Does this break Docker setup? (Verify setup_dev.sh still works)
10. **Did I update documentation?** (CHANGELOG.md, README.md, docs/README.md when phase completes)
11. **Am I implementing features in the wrong sprint?** (Check roadmap for correct sprint assignment)
12. **Did I use shared test fixtures?** (Use `conftest.py` fixtures for test isolation)
13. **Did I respect API contract?** (No breaking changes to frozen contracts)


---
